{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edea7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d2e80",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb335e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_root': './data',\n",
    "    'batch_size': 64,\n",
    "    'num_worker': 0,\n",
    "    \n",
    "    'mlp_arch': [9, 16, 16, 8, 1],\n",
    "    \n",
    "    'trainer': 'Adam',\n",
    "    'num_epoch': 5000,\n",
    "    'learning_rate': 0.001,\n",
    "    'early_stop_epoch': 10,\n",
    "    'save_period': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7879af3",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabf94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c6e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(full_dataset, valid_ratio):\n",
    "    train_set, valid_set = random_split(full_dataset, [1-valid_ratio, valid_ratio])\n",
    "    return train_set, valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918702f2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ef94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bf56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, data_root, training=False, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.training = training\n",
    "        self.transform = transform\n",
    "        \n",
    "        if training:\n",
    "            file_name = 'train.csv'\n",
    "        else:\n",
    "            file_name = 'test.csv'\n",
    "            \n",
    "        self.dataset = pd.read_csv(os.path.join(data_root, file_name))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        pclass = np.array(self.dataset['Pclass'][idx], dtype=np.float64)\n",
    "        name = self.dataset['Name'][idx] # not used\n",
    "        sex = np.array(pd.get_dummies(self.dataset['Sex']).iloc[idx], dtype=np.float64)\n",
    "        age = np.array(self.dataset['Age'][idx] if not np.isnan(self.dataset['Age'][idx]) else -1, dtype=np.float64)\n",
    "        sibsp = np.array(self.dataset['SibSp'][idx], dtype=np.float64)\n",
    "        parch = np.array(self.dataset['Parch'][idx], dtype=np.float64)\n",
    "        ticket = self.dataset['Ticket'][idx] # not used\n",
    "        fare = np.array(self.dataset['Fare'][idx], dtype=np.float64)\n",
    "        cabin = self.dataset['Cabin'][idx] # not used\n",
    "        embarked = np.array(pd.get_dummies(self.dataset['Embarked']).iloc[idx], dtype=np.float64)\n",
    "        \n",
    "        if self.training:\n",
    "            label = np.array(self.dataset['Survived'][idx], dtype=np.float64).item()\n",
    "        else:\n",
    "            label = None\n",
    "        \n",
    "        # feature: [paclass, female, male, age, sibsp, parch, fare, embarked(C), embarked(Q), embarked(S)]\n",
    "        feature = np.concatenate((pclass, sex, age, sibsp, parch, fare, embarked), axis=None)\n",
    "        sample = {'feature': feature, 'label': label}\n",
    "        if self.transform:\n",
    "            return self.transform(sample)\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecc60dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': array([ 1. ,  1. ,  0. , 35. ,  1. ,  0. , 53.1,  0. ,  0. ,  1. ]),\n",
       " 'label': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TitanicDataset(data_root=config['data_root'], training=True)\n",
    "train_set, valid_set = train_valid_split(dataset, 0.1)\n",
    "dataset.__getitem__(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262c16b",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4c7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e33f5db",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbb36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data: dict) -> dict:\n",
    "        for k, v in data.items():\n",
    "            data[k] = torch.from_numpy(v).to(dtype=torch.get_default_dtype())\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70623c",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bec9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eaa31427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, mlp_arch):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(*[\n",
    "            self.mlp_block(mlp_arch[i-1], mlp_arch[i]) for i in range(1, len(mlp_arch)-1)\n",
    "        ])\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(mlp_arch[-2], mlp_arch[-1]),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def mlp_block(self, dim_input, dim_output):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(dim_input, dim_output),\n",
    "            nn.ReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a1a442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = SurvivalNet([2,2,1])\n",
    "input_t = torch.Tensor([1.0, 2.0])\n",
    "print(net(input_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7598f",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5965b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e8446",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5658c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accurancy(prediction, target):\n",
    "    assert len(prediction) == len(target)\n",
    "    predition = torch.round(prediction)\n",
    "    correct = torch.sum(torch.abs(prediction - target))\n",
    "    return correct / len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eca94e",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35204fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e40acd0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self,\n",
    "        num_epoch, train_data_loader, valid_data_loader, model, optimizer, lr_scheduler, criterion, metric, early_stop_epoch, save_period, device\n",
    "    ):\n",
    "        self.num_epoch = num_epoch\n",
    "        \n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.valid_data_loader = valid_data_loader\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.criterion = criterion\n",
    "        self.metric = metric\n",
    "        self.early_stop_epoch = early_stop_epoch\n",
    "        self.save_period = save_period\n",
    "        self.device = device\n",
    "        \n",
    "        self.acc_best = 0\n",
    "        self.not_improved_count = 0\n",
    "        self.writer = SummaryWriter('./run/log')\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(self.num_epoch):\n",
    "            self.__train_epoch(epoch)\n",
    "            self.__valid_epoch(epoch)\n",
    "    \n",
    "    def __train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        for batch_idx, data in tqdm(enumerate(self.train_data_loader), desc=f'Epoch {epoch}: '):\n",
    "            feature = data['feature'].to(self.device)\n",
    "            label = data['label'].to(self.device)\n",
    "            print(type(feature))\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(feature)\n",
    "            loss = self.criterion(output, label)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # record improved or not\n",
    "            acc = self.metric(output, label)\n",
    "            improved = (acc > self.acc_best)\n",
    "            if improved:\n",
    "                self.not_improved_count = 0\n",
    "                self.acc_best = acc\n",
    "            else:\n",
    "                self.not_improved_count += 1\n",
    "            \n",
    "            # early stop\n",
    "            if self.not_improved_count >= self.early_stop:\n",
    "                self.early_stop = True\n",
    "            \n",
    "            # learning rate scheduler\n",
    "            if lr_scheduler:\n",
    "                self.lr_scheduler.step()\n",
    "            \n",
    "            # save model\n",
    "            if epoch % self.save_period == 0:\n",
    "                torch.save(model.state_dict(), './run/model')\n",
    "            \n",
    "            # tensorboard\n",
    "            self.writer.add_scalar('Loss/Train loss', loss.item(), epoch)\n",
    "            self.writer.add_scalar('Accuracy/Train acc', acc, epoch)\n",
    "    \n",
    "    def __valid_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(self.valid_data_loader):\n",
    "                feature = data['feature'].to(self.device)\n",
    "                label = data['label'].to(self.device)\n",
    "\n",
    "                output = self.model(feature)\n",
    "                loss = self.criterion(output, label)\n",
    "                acc = self.metric(output, label)\n",
    "\n",
    "\n",
    "                # tensorboard\n",
    "                self.writer.add_scalar('Loss/Valid loss', loss.item(), epoch)\n",
    "                self.writer.add_scalar('Accuracy/Valid acc', acc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7666f6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e8feadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 40\u001b[0m\n\u001b[1;32m     20\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(\n\u001b[1;32m     21\u001b[0m     optimizer,\n\u001b[1;32m     22\u001b[0m     step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     23\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     27\u001b[0m     num_epoch\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     28\u001b[0m     train_data_loader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     device \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 26\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epoch):\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__valid_epoch(epoch)\n",
      "Cell \u001b[0;32mIn[52], line 37\u001b[0m, in \u001b[0;36mTrainer.__train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(feature))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, label)\n\u001b[1;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m, in \u001b[0;36mSurvivalNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "dataset = TitanicDataset(data_root=config['data_root'], training=True)\n",
    "train_set, valid_set = train_valid_split(dataset, 0.1)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_worker'])\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_worker'])\n",
    "\n",
    "model = SurvivalNet(config['mlp_arch'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainable_params,\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=0,\n",
    "    amsgrad=True\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=50,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    num_epoch=config['num_epoch'],\n",
    "    train_data_loader=train_dataloader,\n",
    "    valid_data_loader=valid_dataloader,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    criterion=loss,\n",
    "    metric=accurancy,\n",
    "    early_stop_epoch=config['early_stop_epoch'],\n",
    "    save_period = config['save_period'],\n",
    "    device = device\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74e6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a2cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11702234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

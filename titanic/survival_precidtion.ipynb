{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edea7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmj/anaconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d2e80",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb335e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_root': './data',\n",
    "    'batch_size': 64,\n",
    "    'num_worker': 2,\n",
    "    \n",
    "    'trainer': 'Adam',\n",
    "    'epoch': 5000,\n",
    "    'early_stop': 10,\n",
    "    'save_period': 1,\n",
    "    'device': 'mps'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7879af3",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabf94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c6e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(full_dataset, valid_ratio):\n",
    "    train_set, valid_set = random_split(full_dataset, [1-valid_ratio, valid_ratio])\n",
    "    return train_set, valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918702f2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ef94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29bf56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, data_root, training=False, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.training = training\n",
    "        self.transform = transform\n",
    "        \n",
    "        if training:\n",
    "            file_name = 'train.csv'\n",
    "        else:\n",
    "            file_name = 'test.csv'\n",
    "            \n",
    "        self.dataset = pd.read_csv(os.path.join(data_root, file_name))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        pclass = np.array(self.dataset['Pclass'][idx], dtype=np.float64)\n",
    "        name = self.dataset['Name'][idx] # not used\n",
    "        sex = np.array(pd.get_dummies(self.dataset['Sex']).iloc[idx], dtype=np.float64)\n",
    "        age = np.array(self.dataset['Age'][idx] if not np.isnan(self.dataset['Age'][idx]) else -1, dtype=np.float64)\n",
    "        sibsp = np.array(self.dataset['SibSp'][idx], dtype=np.float64)\n",
    "        parch = np.array(self.dataset['Parch'][idx], dtype=np.float64)\n",
    "        ticket = self.dataset['Ticket'][idx] # not used\n",
    "        fare = np.array(self.dataset['Fare'][idx], dtype=np.float64)\n",
    "        cabin = self.dataset['Cabin'][idx] # not used\n",
    "        embarked = np.array(pd.get_dummies(self.dataset['Embarked']).iloc[idx], dtype=np.float64)\n",
    "        \n",
    "        if self.training:\n",
    "            label = np.array(self.dataset['Survived'][idx], dtype=np.float64).item()\n",
    "        else:\n",
    "            label = None\n",
    "        \n",
    "        # feature: [paclass, female, male, age, sibsp, parch, fare, embarked(C), embarked(Q), embarked(S)]\n",
    "        feature = np.concatenate((pclass, sex, age, sibsp, parch, fare, embarked), axis=None)\n",
    "        sample = {'feature': feature, 'label': label}\n",
    "        if self.transform:\n",
    "            return self.transform(sample)\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecc60dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': array([ 1. ,  1. ,  0. , 35. ,  1. ,  0. , 53.1,  0. ,  0. ,  1. ]),\n",
       " 'label': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TitanicDataset(data_root=config['data_root'], training=True, transform=)\n",
    "train_set, valid_set = train_valid_split(dataset, 0.1)\n",
    "dataset.__getitem__(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262c16b",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4c7375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmj/anaconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/lmj/anaconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e33f5db",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bbb36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data: dict) -> dict:\n",
    "        for k, v in data.items():\n",
    "            data[k] = torch.from_numpy(v).to(dtype=torch.get_default_dtype())\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70623c",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5bec9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa31427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, mlp_arch):\n",
    "        self.mlp = nn.Sequential([\n",
    "            self.mlp_block(mlp_arch[i-1], mlp_arch[i]) for i in range(1, len(mlp_arch)-1)\n",
    "        ])\n",
    "        self.output_layer = nn.Sequential([\n",
    "            nn.Linear(mlp_arch[-2], mlp_arch[-1]),\n",
    "            nn.Softmax()\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def mlp_block(self, dim_input, dim_output):\n",
    "        return nn.Sequential([\n",
    "            nn.Linear(dim_input, dim_output),\n",
    "            nn.ReLU()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7598f",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5965b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e8446",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5658c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accurancy(prediction, target):\n",
    "    assert len(prediction) == len(target)\n",
    "    predition = torch.round(prediction)\n",
    "    correct = torch.sum(torch.abs(prediction - target))\n",
    "    return correct / len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eca94e",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf7666f6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8feadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74e6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a2cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11702234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
